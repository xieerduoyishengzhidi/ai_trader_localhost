#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
å°† pentosh_all.csv å¯¼å…¥ ChromaDB
ä½¿ç”¨é¢„è®¡ç®—çš„å‘é‡ï¼ˆembedding_contextåˆ—ï¼‰ï¼Œä¸éœ€è¦é…ç½® Embedding Function
"""

import csv
import json
import os
import sys
from pathlib import Path
from typing import List, Dict, Any, Optional

try:
    import chromadb
except ImportError:
    print("âŒ è¯·å…ˆå®‰è£… chromadb: pip install chromadb")
    print("   è¿è¡Œå‘½ä»¤: pip install -r rag/requirements.txt")
    sys.exit(1)

# é…ç½®
CSV_FILE = Path(__file__).parent.parent / "pentosh_all.csv"
CHROMA_DB_PATH = Path(__file__).parent / "chroma_db"
COLLECTION_NAME = "pentosh_tweets"

# ç”¨äºæ„å»ºæ–‡æ¡£æ–‡æœ¬çš„å­—æ®µ
TEXT_FIELDS = [
    "text",
    "info_overall_assessment",
    "gpt_explanation",
    "gpt_reason",
]

# ç”¨äºå…ƒæ•°æ®çš„å­—æ®µ
METADATA_FIELDS = [
    "id",
    "tweet_id",
    "tweet_url",
    "screen_name",
    "display_name",
    "created_at",
    "gpt_sentiment",
    "gpt_assets",
    "info_final_score",
    "is_market_related",
]


def parse_embedding(embedding_str: str) -> Optional[List[float]]:
    """è§£æ embedding_context åˆ—çš„å‘é‡æ•°æ®"""
    if not embedding_str or embedding_str.strip() == "":
        return None
    
    try:
        # å°è¯•è§£æ JSON æ•°ç»„
        embedding = json.loads(embedding_str)
        if isinstance(embedding, list):
            return [float(x) for x in embedding]
    except (json.JSONDecodeError, ValueError, TypeError):
        pass
    
    return None


def build_document_text(row: Dict[str, Any]) -> str:
    """æ„å»ºæ–‡æ¡£æ–‡æœ¬"""
    parts = []
    for field in TEXT_FIELDS:
        value = row.get(field, "")
        if value and str(value).strip():
            parts.append(str(value).strip())
    
    return " | ".join(parts) if parts else row.get("text", "")


def build_metadata(row: Dict[str, Any]) -> Dict[str, Any]:
    """æ„å»ºå…ƒæ•°æ®"""
    metadata = {}
    for field in METADATA_FIELDS:
        value = row.get(field)
        if value is not None:
            # ChromaDB å…ƒæ•°æ®å€¼å¿…é¡»æ˜¯å­—ç¬¦ä¸²ã€æ•°å­—æˆ–å¸ƒå°”å€¼
            if isinstance(value, (str, int, float, bool)):
                metadata[field] = value
            elif isinstance(value, list):
                # åˆ—è¡¨è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²
                metadata[field] = json.dumps(value)
            elif isinstance(value, dict):
                # å­—å…¸è½¬æ¢ä¸º JSON å­—ç¬¦ä¸²
                metadata[field] = json.dumps(value)
            else:
                metadata[field] = str(value)
    
    return metadata


def import_csv_to_chromadb(csv_path: Path, db_path: Path, collection_name: str):
    """å°† CSV æ–‡ä»¶å¯¼å…¥ ChromaDB"""
    
    if not csv_path.exists():
        print(f"âŒ CSV æ–‡ä»¶ä¸å­˜åœ¨: {csv_path}")
        return False
    
    print(f"ğŸ“‚ è¯»å– CSV æ–‡ä»¶: {csv_path}")
    
    # åˆå§‹åŒ– ChromaDB å®¢æˆ·ç«¯ï¼ˆæŒä¹…åŒ–æ¨¡å¼ï¼‰
    print(f"ğŸ”§ åˆå§‹åŒ– ChromaDBï¼Œæ•°æ®åº“è·¯å¾„: {db_path}")
    client = chromadb.PersistentClient(path=str(db_path))
    
    # è·å–æˆ–åˆ›å»ºé›†åˆ
    # æ³¨æ„ï¼šä¸è®¾ç½® embedding_functionï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨é¢„è®¡ç®—çš„å‘é‡
    print(f"ğŸ“¦ è·å–/åˆ›å»ºé›†åˆ: {collection_name}")
    
    # å¦‚æœé›†åˆå·²å­˜åœ¨ï¼Œè¯¢é—®æ˜¯å¦åˆ é™¤é‡å»º
    try:
        existing_collection = client.get_collection(name=collection_name)
        existing_count = existing_collection.count()
        print(f"âš ï¸  é›†åˆå·²å­˜åœ¨ï¼ŒåŒ…å« {existing_count} æ¡æ•°æ®")
        print(f"   å°†åˆ é™¤æ—§æ•°æ®å¹¶é‡æ–°å¯¼å…¥...")
        client.delete_collection(name=collection_name)
    except Exception:
        pass  # é›†åˆä¸å­˜åœ¨ï¼Œç»§ç»­åˆ›å»º
    
    collection = client.create_collection(
        name=collection_name,
        metadata={"description": "Pentoshi tweets with pre-computed embeddings"}
    )
    
    # è¯»å– CSV æ–‡ä»¶
    documents = []
    embeddings = []
    metadatas = []
    ids = []
    
    total_rows = 0
    valid_rows = 0
    
    with open(csv_path, 'r', encoding='utf-8') as f:
        reader = csv.DictReader(f)
        
        for row in reader:
            total_rows += 1
            
            # è§£æå‘é‡
            embedding = parse_embedding(row.get("embedding_context", ""))
            if embedding is None:
                print(f"âš ï¸  ç¬¬ {total_rows} è¡Œç¼ºå°‘æœ‰æ•ˆçš„å‘é‡æ•°æ®ï¼Œè·³è¿‡")
                continue
            
            # æ„å»ºæ–‡æ¡£æ–‡æœ¬
            doc_text = build_document_text(row)
            if not doc_text:
                print(f"âš ï¸  ç¬¬ {total_rows} è¡Œæ²¡æœ‰æ–‡æœ¬å†…å®¹ï¼Œè·³è¿‡")
                continue
            
            # æ„å»ºå…ƒæ•°æ®
            metadata = build_metadata(row)
            
            # ä½¿ç”¨ id ä½œä¸ºæ–‡æ¡£ ID
            doc_id = str(row.get("id", f"row_{total_rows}"))
            
            documents.append(doc_text)
            embeddings.append(embedding)
            metadatas.append(metadata)
            ids.append(doc_id)
            
            valid_rows += 1
            
            # æ¯å¤„ç† 100 æ¡æ˜¾ç¤ºè¿›åº¦
            if valid_rows % 100 == 0:
                print(f"âœ… å·²å¤„ç† {valid_rows} æ¡æœ‰æ•ˆæ•°æ®...")
    
    print(f"\nğŸ“Š ç»Ÿè®¡ä¿¡æ¯:")
    print(f"   - æ€»è¡Œæ•°: {total_rows}")
    print(f"   - æœ‰æ•ˆæ•°æ®: {valid_rows}")
    print(f"   - è·³è¿‡æ•°æ®: {total_rows - valid_rows}")
    
    if valid_rows == 0:
        print("âŒ æ²¡æœ‰æœ‰æ•ˆæ•°æ®å¯å¯¼å…¥")
        return False
    
    # æ‰¹é‡æ·»åŠ åˆ° ChromaDB
    print(f"\nğŸš€ å¼€å§‹å¯¼å…¥åˆ° ChromaDB...")
    batch_size = 100
    
    for i in range(0, len(ids), batch_size):
        batch_ids = ids[i:i+batch_size]
        batch_documents = documents[i:i+batch_size]
        batch_embeddings = embeddings[i:i+batch_size]
        batch_metadatas = metadatas[i:i+batch_size]
        
        try:
            collection.add(
                ids=batch_ids,
                documents=batch_documents,
                embeddings=batch_embeddings,
                metadatas=batch_metadatas
            )
            print(f"âœ… å·²å¯¼å…¥æ‰¹æ¬¡ {i//batch_size + 1}/{(len(ids)-1)//batch_size + 1} ({len(batch_ids)} æ¡)")
        except Exception as e:
            print(f"âŒ å¯¼å…¥æ‰¹æ¬¡ {i//batch_size + 1} å¤±è´¥: {e}")
            return False
    
    # éªŒè¯å¯¼å…¥ç»“æœ
    count = collection.count()
    print(f"\nâœ… å¯¼å…¥å®Œæˆï¼ChromaDB é›†åˆä¸­å…±æœ‰ {count} æ¡æ•°æ®")
    
    # æµ‹è¯•æŸ¥è¯¢
    print(f"\nğŸ” æµ‹è¯•æŸ¥è¯¢...")
    try:
        results = collection.query(
            query_embeddings=[embeddings[0]],
            n_results=3
        )
        print(f"âœ… æŸ¥è¯¢æµ‹è¯•æˆåŠŸï¼Œè¿”å› {len(results['ids'][0])} æ¡ç»“æœ")
    except Exception as e:
        print(f"âš ï¸  æŸ¥è¯¢æµ‹è¯•å¤±è´¥: {e}")
    
    return True


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ“¥ å°† pentosh_all.csv å¯¼å…¥ ChromaDB")
    print("=" * 60)
    print()
    
    # æ£€æŸ¥ CSV æ–‡ä»¶
    if not CSV_FILE.exists():
        print(f"âŒ CSV æ–‡ä»¶ä¸å­˜åœ¨: {CSV_FILE}")
        print(f"   è¯·ç¡®ä¿æ–‡ä»¶ä½äºé¡¹ç›®æ ¹ç›®å½•")
        return 1
    
    # åˆ›å»ºæ•°æ®åº“ç›®å½•
    CHROMA_DB_PATH.mkdir(parents=True, exist_ok=True)
    
    # å¯¼å…¥æ•°æ®
    success = import_csv_to_chromadb(
        csv_path=CSV_FILE,
        db_path=CHROMA_DB_PATH,
        collection_name=COLLECTION_NAME
    )
    
    if success:
        print("\n" + "=" * 60)
        print("âœ… å¯¼å…¥æˆåŠŸï¼")
        print(f"ğŸ“‚ æ•°æ®åº“è·¯å¾„: {CHROMA_DB_PATH}")
        print(f"ğŸ“¦ é›†åˆåç§°: {COLLECTION_NAME}")
        print("=" * 60)
        return 0
    else:
        print("\n" + "=" * 60)
        print("âŒ å¯¼å…¥å¤±è´¥")
        print("=" * 60)
        return 1


if __name__ == "__main__":
    sys.exit(main())

