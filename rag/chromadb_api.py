#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ChromaDB RAG HTTP API æœåŠ¡
ä¸º Go ä»£ç æä¾› ChromaDB æŸ¥è¯¢æ¥å£
æ”¯æŒ BM25 + å‘é‡æ··åˆæœç´¢ï¼ˆHybrid Searchï¼‰

BM25 æœç´¢å­—æ®µï¼š
- documents å­—æ®µï¼ˆåŒ…å« text, info_overall_assessment, gpt_explanation, gpt_reasonï¼‰

å…ƒæ•°æ®è¿‡æ»¤ï¼š
- æ•°æ®åº“å±‚é¢ï¼šscreen_name (trader_name), gpt_sentiment (sentiment), is_market_related
- ç»“æœå±‚é¢ï¼šgpt_assets (asset) - JSON æ•°ç»„ï¼Œéœ€è¦è§£æåè¿‡æ»¤
"""

import json
import os
import sys
import io
from pathlib import Path
from typing import List, Dict, Any, Optional, Tuple
from collections import defaultdict

try:
    from flask import Flask, request, jsonify
except ImportError:
    print("âŒ è¯·å…ˆå®‰è£… flask: pip install flask")
    sys.exit(1)

try:
    import chromadb
except ImportError:
    print("âŒ è¯·å…ˆå®‰è£… chromadb: pip install chromadb")
    sys.exit(1)

try:
    from rank_bm25 import BM25Okapi
except ImportError:
    print("âŒ è¯·å…ˆå®‰è£… rank-bm25: pip install rank-bm25")
    sys.exit(1)

try:
    from sentence_transformers import SentenceTransformer
except ImportError:
    print("âŒ è¯·å…ˆå®‰è£… sentence-transformers: pip install sentence-transformers")
    sys.exit(1)

# ä¿®å¤ Windows æ§åˆ¶å°ç¼–ç é—®é¢˜
if sys.platform == 'win32':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

# é…ç½®
CHROMA_DB_PATH = Path(__file__).parent / "chroma_db"
COLLECTION_NAME = "pentosh_tweets"
DEFAULT_PORT = 8765

# Embedding æ¨¡å‹é…ç½®ï¼ˆä¸å¯¼å…¥æ—¶ä½¿ç”¨çš„æ¨¡å‹ä¸€è‡´ï¼‰
EMBEDDING_MODEL = os.getenv("EMBEDDING_MODEL", "moka-ai/m3e-base")

app = Flask(__name__)

# å…¨å±€å˜é‡
_client = None
_collection = None
_embedding_model = None
_bm25_index = None  # BM25 ç´¢å¼•ç¼“å­˜
_documents_cache = None  # æ–‡æ¡£ç¼“å­˜ï¼ˆç”¨äº BM25ï¼‰


def get_collection():
    """è·å– ChromaDB é›†åˆï¼ˆæ‡’åŠ è½½ï¼‰"""
    global _client, _collection
    
    if _collection is None:
        _client = chromadb.PersistentClient(path=str(CHROMA_DB_PATH))
        try:
            _collection = _client.get_collection(name=COLLECTION_NAME)
        except Exception as e:
            raise RuntimeError(f"æ— æ³•è·å–é›†åˆ '{COLLECTION_NAME}': {e}")
    
    return _collection


def get_embedding_model():
    """è·å– Embedding æ¨¡å‹ï¼ˆæ‡’åŠ è½½ï¼‰"""
    global _embedding_model
    
    if _embedding_model is None:
        print(f"ğŸ“¦ åŠ è½½ Embedding æ¨¡å‹: {EMBEDDING_MODEL}")
        _embedding_model = SentenceTransformer(EMBEDDING_MODEL)
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ")
    
    return _embedding_model


def build_bm25_index(collection, trader_name: Optional[str] = None, where_clause: Optional[Dict] = None):
    """æ„å»º BM25 ç´¢å¼•ï¼ˆå¸¦ç¼“å­˜ï¼‰
    
    Args:
        collection: ChromaDB é›†åˆ
        trader_name: äº¤æ˜“å‘˜åç§°ï¼ˆç”¨äºç¼“å­˜é”®ï¼Œå·²åºŸå¼ƒï¼Œä¿ç•™å…¼å®¹æ€§ï¼‰
        where_clause: where è¿‡æ»¤æ¡ä»¶ï¼ˆæ•°æ®åº“å±‚é¢è¿‡æ»¤ï¼Œé«˜æ•ˆï¼‰
    
    Note:
        BM25 ç´¢å¼•åœ¨ documents å­—æ®µä¸Šæ„å»ºï¼Œè¯¥å­—æ®µåŒ…å«ï¼š
        - text (åŸå§‹æ¨æ–‡æ–‡æœ¬)
        - info_overall_assessment (ç»¼åˆè¯„ä¼°)
        - gpt_explanation (GPT è§£é‡Š)
        - gpt_reason (GPT åŸå› )
    """
    global _bm25_index, _documents_cache
    
    # æ„å»ºç¼“å­˜é”®ï¼ˆåŸºäº where_clauseï¼‰
    cache_key = str(where_clause) if where_clause else "all"
    
    # å¦‚æœå·²æœ‰ç¼“å­˜ä¸”æ¡ä»¶åŒ¹é…ï¼Œç›´æ¥è¿”å›
    if _bm25_index is not None and _documents_cache is not None:
        if where_clause is None or cache_key == "all":
            return _bm25_index, _documents_cache
    
    # ä½¿ç”¨ ChromaDB çš„ where è¿‡æ»¤ï¼ˆæ•°æ®åº“å±‚é¢ï¼Œé«˜æ•ˆï¼‰
    # å¦‚æœæ²¡æœ‰æä¾› where_clauseï¼Œå°è¯•ä½¿ç”¨ trader_nameï¼ˆå‘åå…¼å®¹ï¼‰
    if where_clause is None and trader_name:
        where_clause = {"screen_name": trader_name}
    
    try:
        # ä½¿ç”¨ where è¿‡æ»¤è·å–æ•°æ®ï¼ˆæ•°æ®åº“å±‚é¢è¿‡æ»¤ï¼Œé«˜æ•ˆï¼‰
        if where_clause:
            results = collection.get(where=where_clause)
        else:
            results = collection.get()
    except Exception:
        # å¦‚æœ where æŸ¥è¯¢å¤±è´¥ï¼ˆæ¯”å¦‚å­—æ®µä¸å­˜åœ¨ï¼‰ï¼Œfallback åˆ°è·å–æ‰€æœ‰æ•°æ®
        results = collection.get()
    
    if not results['ids']:
        # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œå°è¯•æ¨¡ç³ŠåŒ¹é…ï¼ˆä½†åªåœ¨å†…å­˜ä¸­è¿‡æ»¤å°‘é‡æ•°æ®ï¼‰
        if trader_name:
            # å…ˆè·å–å°‘é‡æ•°æ®å°è¯•åŒ¹é…
            all_results = collection.get(limit=100)
            filtered_ids = []
            filtered_docs = []
            filtered_metadatas = []
            
            for doc_id, doc, metadata in zip(
                all_results['ids'],
                all_results['documents'],
                all_results['metadatas']
            ):
                screen_name = metadata.get('screen_name', '')
                display_name = metadata.get('display_name', '')
                if (trader_name.lower() in screen_name.lower() or 
                    trader_name.lower() in display_name.lower()):
                    filtered_ids.append(doc_id)
                    filtered_docs.append(doc)
                    filtered_metadatas.append(metadata)
            
            if filtered_ids:
                results = {
                    'ids': filtered_ids,
                    'documents': filtered_docs,
                    'metadatas': filtered_metadatas
                }
            else:
                # å¦‚æœè¿˜æ˜¯æ‰¾ä¸åˆ°ï¼Œè¿”å›ç©ºç´¢å¼•
                return None, None
    
    # å‡†å¤‡ BM25 æ•°æ®
    documents = results['documents']
    if not documents:
        return None, None
    
    # åˆ†è¯ï¼ˆç®€å•çš„ä¸­è‹±æ–‡åˆ†è¯ï¼‰
    tokenized_docs = []
    for doc in documents:
        # ç®€å•åˆ†è¯ï¼šæŒ‰ç©ºæ ¼å’Œæ ‡ç‚¹åˆ†å‰²ï¼Œä¿ç•™å­—æ¯æ•°å­—å’Œä¸­æ–‡
        import re
        tokens = re.findall(r'\b\w+\b|[\u4e00-\u9fff]+', doc.lower())
        tokenized_docs.append(tokens)
    
    # æ„å»º BM25 ç´¢å¼•
    bm25 = BM25Okapi(tokenized_docs)
    
    # ç¼“å­˜
    _bm25_index = bm25
    _documents_cache = {
        'ids': results['ids'],
        'documents': results['documents'],
        'metadatas': results.get('metadatas', [])
    }
    
    return bm25, _documents_cache


def rrf_merge(vector_results: List[Tuple[str, float]], 
              bm25_results: List[Tuple[str, float]], 
              k: int = 60) -> List[str]:
    """Reciprocal Rank Fusion (RRF) åˆå¹¶æœç´¢ç»“æœ
    
    Args:
        vector_results: [(doc_id, score), ...] å‘é‡æœç´¢ç»“æœ
        bm25_results: [(doc_id, score), ...] BM25 æœç´¢ç»“æœ
        k: RRF å¸¸æ•°ï¼ˆé»˜è®¤ 60ï¼‰
    
    Returns:
        åˆå¹¶åçš„æ–‡æ¡£ ID åˆ—è¡¨ï¼ˆæŒ‰ RRF åˆ†æ•°æ’åºï¼‰
    """
    # æ„å»ºæ–‡æ¡£ ID åˆ°æ’åçš„æ˜ å°„
    vector_ranks = {doc_id: rank + 1 for rank, (doc_id, _) in enumerate(vector_results)}
    bm25_ranks = {doc_id: rank + 1 for rank, (doc_id, _) in enumerate(bm25_results)}
    
    # è®¡ç®— RRF åˆ†æ•°
    rrf_scores = defaultdict(float)
    all_doc_ids = set(vector_ranks.keys()) | set(bm25_ranks.keys())
    
    for doc_id in all_doc_ids:
        if doc_id in vector_ranks:
            rrf_scores[doc_id] += 1.0 / (k + vector_ranks[doc_id])
        if doc_id in bm25_ranks:
            rrf_scores[doc_id] += 1.0 / (k + bm25_ranks[doc_id])
    
    # æŒ‰ RRF åˆ†æ•°æ’åº
    sorted_docs = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)
    
    return [doc_id for doc_id, _ in sorted_docs]


def build_where_clause(trader_name: Optional[str] = None, 
                       asset: Optional[str] = None,
                       sentiment: Optional[str] = None,
                       is_market_related: Optional[bool] = None) -> Optional[Dict[str, Any]]:
    """æ„å»º ChromaDB where è¿‡æ»¤æ¡ä»¶
    
    Args:
        trader_name: äº¤æ˜“å‘˜åç§°ï¼ˆåŒ¹é… screen_nameï¼‰
        asset: æ ‡çš„èµ„äº§ï¼ˆåŒ¹é… gpt_assets JSON æ•°ç»„ï¼‰
        sentiment: æƒ…æ„Ÿï¼ˆpositive/negativeï¼ŒåŒ¹é… gpt_sentimentï¼‰
        is_market_related: æ˜¯å¦å¸‚åœºç›¸å…³ï¼ˆåŒ¹é… is_market_relatedï¼‰
    
    Returns:
        where æ¡ä»¶å­—å…¸ï¼Œæˆ– None
    """
    where_parts = []
    
    if trader_name:
        where_parts.append({"screen_name": trader_name})
    
    if sentiment:
        where_parts.append({"gpt_sentiment": sentiment})
    
    if is_market_related is not None:
        where_parts.append({"is_market_related": is_market_related})
    
    # asset éœ€è¦ç‰¹æ®Šå¤„ç†ï¼Œå› ä¸º gpt_assets æ˜¯ JSON å­—ç¬¦ä¸²
    # ChromaDB ä¸æ”¯æŒ JSON æ•°ç»„æŸ¥è¯¢ï¼Œéœ€è¦åœ¨ç»“æœä¸­è¿‡æ»¤
    # è¿™é‡Œå…ˆä¸åŠ å…¥ whereï¼Œåç»­åœ¨ç»“æœä¸­è¿‡æ»¤
    
    if len(where_parts) == 0:
        return None
    elif len(where_parts) == 1:
        return where_parts[0]
    else:
        # ChromaDB æ”¯æŒ $and æ“ä½œç¬¦
        return {"$and": where_parts}


def filter_by_asset(results: List[Dict[str, Any]], asset: Optional[str] = None, 
                    assets: Optional[List[str]] = None) -> List[Dict[str, Any]]:
    """åœ¨ç»“æœä¸­è¿‡æ»¤åŒ…å«æŒ‡å®šèµ„äº§çš„æ–‡æ¡£
    
    Args:
        results: æœç´¢ç»“æœåˆ—è¡¨
        asset: å•ä¸ªèµ„äº§åç§°ï¼ˆå¦‚ "SOL", "BTC"ï¼‰ï¼Œä¸ assets äºŒé€‰ä¸€
               - ç‰¹æ®Šå€¼ "blur" è¡¨ç¤ºä¸è¿›è¡Œèµ„äº§è¿‡æ»¤
        assets: å¤šä¸ªèµ„äº§åç§°åˆ—è¡¨ï¼ˆå¦‚ ["SOL", "BTC"]ï¼‰ï¼Œä¸ asset äºŒé€‰ä¸€
                - å¦‚æœåŒ…å« "blur"ï¼Œåˆ™ä¸è¿›è¡Œèµ„äº§è¿‡æ»¤
    
    Returns:
        è¿‡æ»¤åçš„ç»“æœåˆ—è¡¨
    
    Note:
        - å¦‚æœåŒæ—¶æä¾› asset å’Œ assetsï¼Œä¼˜å…ˆä½¿ç”¨ assets
        - å¦‚æœ assets åŒ…å«å¤šä¸ªèµ„äº§ï¼Œè¿”å›åŒ…å«ä»»æ„ä¸€ä¸ªèµ„äº§çš„æ–‡æ¡£ï¼ˆOR é€»è¾‘ï¼‰
        - å¦‚æœ asset="blur" æˆ– assets åŒ…å« "blur"ï¼Œè·³è¿‡èµ„äº§è¿‡æ»¤
    """
    # æ£€æŸ¥ blur é€‰é¡¹
    if asset and asset.lower() == "blur":
        return results
    
    if assets:
        # æ£€æŸ¥ assets åˆ—è¡¨ä¸­æ˜¯å¦åŒ…å« "blur"
        if any(str(a).lower() == "blur" for a in assets):
            return results
        target_assets = [a.upper() for a in assets if a and str(a).lower() != "blur"]
    elif asset:
        target_assets = [asset.upper()]
    else:
        return results
    
    if not target_assets:
        return results
    
    filtered = []
    
    for result in results:
        metadata = result.get('metadata', {})
        gpt_assets_str = metadata.get('gpt_assets', '[]')
        
        try:
            # è§£æ JSON å­—ç¬¦ä¸²
            gpt_assets = json.loads(gpt_assets_str) if isinstance(gpt_assets_str, str) else gpt_assets_str
            if isinstance(gpt_assets, list):
                # æ£€æŸ¥èµ„äº§åˆ—è¡¨ä¸­æ˜¯å¦åŒ…å«ä»»æ„ä¸€ä¸ªç›®æ ‡èµ„äº§
                assets_upper = [a.upper() if isinstance(a, str) else str(a).upper() for a in gpt_assets]
                # OR é€»è¾‘ï¼šåŒ…å«ä»»æ„ä¸€ä¸ªç›®æ ‡èµ„äº§å³å¯
                if any(target_asset in assets_upper for target_asset in target_assets):
                    filtered.append(result)
        except (json.JSONDecodeError, TypeError):
            # å¦‚æœè§£æå¤±è´¥ï¼Œå°è¯•å­—ç¬¦ä¸²åŒ¹é…
            gpt_assets_upper = str(gpt_assets_str).upper()
            if any(target_asset in gpt_assets_upper for target_asset in target_assets):
                filtered.append(result)
    
    return filtered


def hybrid_search(collection, query_text: str, trader_name: Optional[str] = None,
                  asset: Optional[str] = None,
                  assets: Optional[List[str]] = None,
                  sentiment: Optional[str] = None,
                  is_market_related: Optional[bool] = None,
                  limit: int = 20) -> List[Dict[str, Any]]:
    """BM25 + å‘é‡æ··åˆæœç´¢
    
    Args:
        collection: ChromaDB é›†åˆ
        query_text: æŸ¥è¯¢æ–‡æœ¬ï¼ˆBM25 å’Œå‘é‡æœç´¢éƒ½ä½¿ç”¨æ­¤æ–‡æœ¬ï¼‰
        trader_name: äº¤æ˜“å‘˜åç§°ï¼ˆå¯é€‰ï¼Œç”¨äºå…ƒæ•°æ®è¿‡æ»¤ screen_nameï¼‰
        asset: å•ä¸ªæ ‡çš„èµ„äº§ï¼ˆå¯é€‰ï¼Œç”¨äºè¿‡æ»¤ gpt_assetsï¼Œå¦‚ "SOL"ï¼‰
               - ç‰¹æ®Šå€¼ "blur" è¡¨ç¤ºä¸è¿›è¡Œèµ„äº§è¿‡æ»¤
        assets: å¤šä¸ªæ ‡çš„èµ„äº§åˆ—è¡¨ï¼ˆå¯é€‰ï¼Œç”¨äºè¿‡æ»¤ gpt_assetsï¼Œå¦‚ ["SOL", "BTC"]ï¼‰
               - ä¸ asset äºŒé€‰ä¸€ï¼Œå¦‚æœåŒæ—¶æä¾›ï¼Œä¼˜å…ˆä½¿ç”¨ assets
               - è¿”å›åŒ…å«ä»»æ„ä¸€ä¸ªèµ„äº§çš„æ–‡æ¡£ï¼ˆOR é€»è¾‘ï¼‰
               - å¦‚æœåŒ…å« "blur"ï¼Œåˆ™ä¸è¿›è¡Œèµ„äº§è¿‡æ»¤
        sentiment: æƒ…æ„Ÿï¼ˆå¯é€‰ï¼Œpositive/negativeï¼Œç”¨äºè¿‡æ»¤ gpt_sentimentï¼‰
        is_market_related: æ˜¯å¦å¸‚åœºç›¸å…³ï¼ˆå¯é€‰ï¼Œç”¨äºè¿‡æ»¤ is_market_relatedï¼‰
        limit: è¿”å›ç»“æœæ•°é‡
    
    Returns:
        æœç´¢ç»“æœåˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« id, document, metadata, score
    
    Note:
        - BM25 æœç´¢åœ¨ documents å­—æ®µä¸Šè¿›è¡Œï¼ˆåŒ…å« text, info_overall_assessment, gpt_explanation, gpt_reasonï¼‰
        - å…ƒæ•°æ®è¿‡æ»¤åœ¨æ•°æ®åº“å±‚é¢è¿›è¡Œï¼ˆwhere æ¡ä»¶ï¼‰
        - asset/assets è¿‡æ»¤åœ¨ç»“æœå±‚é¢è¿›è¡Œï¼ˆå› ä¸º gpt_assets æ˜¯ JSON æ•°ç»„ï¼‰
    """
    # æ„å»º where è¿‡æ»¤æ¡ä»¶ï¼ˆæ•°æ®åº“å±‚é¢ï¼Œé«˜æ•ˆï¼‰
    where_clause = build_where_clause(trader_name, asset=None, sentiment=sentiment, is_market_related=is_market_related)
    # æ³¨æ„ï¼šasset ä¸åœ¨ where ä¸­ï¼Œå› ä¸º gpt_assets æ˜¯ JSON æ•°ç»„ï¼ŒChromaDB ä¸æ”¯æŒç›´æ¥æŸ¥è¯¢
    
    # 1. BM25 æœç´¢ï¼ˆå…³é”®å­—åŒ¹é…ï¼‰
    # BM25 åœ¨ documents å­—æ®µä¸Šæœç´¢ï¼Œè¯¥å­—æ®µåŒ…å«ï¼š
    # - text (åŸå§‹æ¨æ–‡æ–‡æœ¬)
    # - info_overall_assessment (ç»¼åˆè¯„ä¼°)
    # - gpt_explanation (GPT è§£é‡Š)
    # - gpt_reason (GPT åŸå› )
    bm25_index, bm25_cache = build_bm25_index(collection, trader_name, where_clause)
    
    if bm25_index is None or bm25_cache is None:
        return []
    
    # åˆ†è¯æŸ¥è¯¢æ–‡æœ¬
    import re
    query_tokens = re.findall(r'\b\w+\b|[\u4e00-\u9fff]+', query_text.lower())
    
    # BM25 æœç´¢
    bm25_scores = bm25_index.get_scores(query_tokens)
    bm25_results = []
    for i, score in enumerate(bm25_scores):
        if score > 0:  # åªä¿ç•™æœ‰åŒ¹é…çš„
            bm25_results.append((bm25_cache['ids'][i], score))
    
    # æŒ‰åˆ†æ•°æ’åº
    bm25_results.sort(key=lambda x: x[1], reverse=True)
    bm25_results = bm25_results[:limit * 2]  # å¤šå–ä¸€äº›ç”¨äºåˆå¹¶
    
    # 2. å‘é‡æœç´¢ï¼ˆè¯­ä¹‰åŒ¹é…ï¼‰
    embedding_model = get_embedding_model()
    query_embedding = embedding_model.encode(query_text, convert_to_numpy=True).tolist()
    
    # ä½¿ç”¨ where è¿‡æ»¤ï¼ˆæ•°æ®åº“å±‚é¢ï¼‰
    try:
        vector_results = collection.query(
            query_embeddings=[query_embedding],
            n_results=limit * 2,  # å¤šå–ä¸€äº›ç”¨äºåˆå¹¶
            where=where_clause
        )
    except Exception:
        # å¦‚æœ where æŸ¥è¯¢å¤±è´¥ï¼Œä¸ä½¿ç”¨è¿‡æ»¤
        vector_results = collection.query(
            query_embeddings=[query_embedding],
            n_results=limit * 2
        )
    
    # æ„å»ºå‘é‡æœç´¢ç»“æœï¼ˆChromaDB è¿”å›çš„æ˜¯è·ç¦»ï¼Œéœ€è¦è½¬æ¢ä¸ºåˆ†æ•°ï¼‰
    vector_scores = []
    if vector_results['ids'] and len(vector_results['ids'][0]) > 0:
        # ChromaDB è¿”å› distancesï¼Œè¶Šå°è¶Šç›¸ä¼¼ï¼Œè½¬æ¢ä¸ºåˆ†æ•°ï¼ˆ1 / (1 + distance)ï¼‰
        for i, doc_id in enumerate(vector_results['ids'][0]):
            distance = vector_results['distances'][0][i] if 'distances' in vector_results else 0
            score = 1.0 / (1.0 + distance)  # è½¬æ¢ä¸ºç›¸ä¼¼åº¦åˆ†æ•°
            vector_scores.append((doc_id, score))
    
    # 3. RRF åˆå¹¶
    merged_doc_ids = rrf_merge(vector_scores, bm25_results, k=60)
    
    # 4. æ„å»ºç»“æœ
    # åˆ›å»ºæ–‡æ¡£ ID åˆ°æ–‡æ¡£çš„æ˜ å°„ï¼ˆåˆå¹¶ BM25 å’Œå‘é‡æœç´¢ç»“æœï¼‰
    doc_map = {}
    
    # ä» BM25 ç¼“å­˜æ·»åŠ 
    for i, doc_id in enumerate(bm25_cache['ids']):
        doc_map[doc_id] = {
            'id': doc_id,
            'document': bm25_cache['documents'][i],
            'metadata': bm25_cache['metadatas'][i] if bm25_cache['metadatas'] and i < len(bm25_cache['metadatas']) else {}
        }
    
    # ä»å‘é‡æœç´¢ç»“æœæ·»åŠ ï¼ˆå¯èƒ½åŒ…å« BM25 ç¼“å­˜ä¸­æ²¡æœ‰çš„ï¼‰
    if vector_results['ids'] and len(vector_results['ids'][0]) > 0:
        for i, doc_id in enumerate(vector_results['ids'][0]):
            if doc_id not in doc_map:
                doc_map[doc_id] = {
                    'id': doc_id,
                    'document': vector_results['documents'][0][i] if vector_results['documents'] and i < len(vector_results['documents'][0]) else "",
                    'metadata': vector_results['metadatas'][0][i] if vector_results.get('metadatas') and i < len(vector_results['metadatas'][0]) else {}
                }
    
    # æŒ‰åˆå¹¶åçš„é¡ºåºè¿”å›
    results = []
    for doc_id in merged_doc_ids[:limit]:
        if doc_id in doc_map:
            results.append(doc_map[doc_id])
    
    # 5. èµ„äº§è¿‡æ»¤ï¼ˆåœ¨ç»“æœå±‚é¢ï¼Œå› ä¸º gpt_assets æ˜¯ JSON æ•°ç»„ï¼‰
    # å¦‚æœ asset="blur" æˆ– assets åŒ…å« "blur"ï¼Œè·³è¿‡èµ„äº§è¿‡æ»¤
    should_filter_asset = True
    if asset and asset.lower() == "blur":
        should_filter_asset = False
    elif assets and any(str(a).lower() == "blur" for a in assets):
        should_filter_asset = False
    
    if should_filter_asset and (asset or assets):
        results = filter_by_asset(results, asset=asset, assets=assets)
    
    return results[:limit]  # ç¡®ä¿ä¸è¶…è¿‡ limit


@app.route('/health', methods=['GET'])
def health():
    """å¥åº·æ£€æŸ¥"""
    try:
        collection = get_collection()
        count = collection.count()
        return jsonify({
            "status": "ok",
            "collection": COLLECTION_NAME,
            "count": count,
            "embedding_model": EMBEDDING_MODEL
        })
    except Exception as e:
        return jsonify({
            "status": "error",
            "error": str(e)
        }), 500


@app.route('/query', methods=['POST'])
def query():
    """æ··åˆæœç´¢æŸ¥è¯¢ï¼ˆBM25 + å‘é‡ï¼‰
    
    è¯·æ±‚ä½“:
    {
        "trader_name": "Pentosh1",  # äº¤æ˜“å‘˜åç§°ï¼ˆå¯é€‰ï¼Œå…ƒæ•°æ®è¿‡æ»¤ screen_nameï¼‰
        "asset": "SOL",  # å•ä¸ªæ ‡çš„èµ„äº§ï¼ˆå¯é€‰ï¼Œå…ƒæ•°æ®è¿‡æ»¤ gpt_assetsï¼Œå¦‚ "SOL"ï¼‰
                       # ç‰¹æ®Šå€¼ "blur" è¡¨ç¤ºä¸è¿›è¡Œèµ„äº§è¿‡æ»¤
        "assets": ["SOL", "BTC"],  # å¤šä¸ªæ ‡çš„èµ„äº§ï¼ˆå¯é€‰ï¼Œä¸ asset äºŒé€‰ä¸€ï¼Œè¿”å›åŒ…å«ä»»æ„ä¸€ä¸ªèµ„äº§çš„æ–‡æ¡£ï¼‰
                                  # å¦‚æœåŒ…å« "blur"ï¼Œåˆ™ä¸è¿›è¡Œèµ„äº§è¿‡æ»¤
        "sentiment": "positive",  # æƒ…æ„Ÿï¼ˆå¯é€‰ï¼Œpositive/negativeï¼Œå…ƒæ•°æ®è¿‡æ»¤ gpt_sentimentï¼‰
        "is_market_related": true,  # æ˜¯å¦å¸‚åœºç›¸å…³ï¼ˆå¯é€‰ï¼Œå…ƒæ•°æ®è¿‡æ»¤ is_market_relatedï¼‰
        "query_text": "SOL ä»·æ ¼é¢„æµ‹",  # æŸ¥è¯¢æ–‡æœ¬ï¼ˆå¿…éœ€ï¼Œç”¨äº BM25 å’Œå‘é‡æœç´¢ï¼‰
        "limit": 5  # è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤5
    }
    
    è¿”å›:
    {
        "trader_name": "Pentosh1",
        "viewpoints": ["è§‚ç‚¹1", "è§‚ç‚¹2", ...],
        "error_reason": ""  # å¦‚æœæœ‰é”™è¯¯
    }
    
    Note:
        - BM25 æœç´¢åœ¨ documents å­—æ®µä¸Šè¿›è¡Œï¼ˆåŒ…å« text, info_overall_assessment, gpt_explanation, gpt_reasonï¼‰
        - å…ƒæ•°æ®è¿‡æ»¤åœ¨æ•°æ®åº“å±‚é¢è¿›è¡Œï¼ˆwhere æ¡ä»¶ï¼‰ï¼Œé«˜æ•ˆ
        - asset è¿‡æ»¤åœ¨ç»“æœå±‚é¢è¿›è¡Œï¼ˆå› ä¸º gpt_assets æ˜¯ JSON æ•°ç»„ï¼‰
    """
    try:
        data = request.get_json()
        if not data:
            return jsonify({
                "trader_name": "",
                "viewpoints": [],
                "error_reason": "è¯·æ±‚ä½“ä¸ºç©º"
            }), 400
        
        trader_name = data.get("trader_name", "").strip() or None
        asset = data.get("asset", "").strip() or None
        assets = data.get("assets")  # å¯ä»¥æ˜¯åˆ—è¡¨æˆ– None
        if assets and isinstance(assets, list):
            assets = [a.strip() for a in assets if a and str(a).strip()]
            assets = assets if assets else None
        else:
            assets = None
        sentiment = data.get("sentiment", "").strip() or None
        is_market_related = data.get("is_market_related")
        query_text = data.get("query_text", "").strip()
        limit = int(data.get("limit", 5))
        
        if not query_text:
            return jsonify({
                "trader_name": trader_name or "",
                "viewpoints": [],
                "error_reason": "æŸ¥è¯¢æ–‡æœ¬ä¸ºç©º"
            }), 400
        
        collection = get_collection()
        
        # æ‰§è¡Œæ··åˆæœç´¢
        results = hybrid_search(
            collection, 
            query_text, 
            trader_name=trader_name,
            asset=asset,
            assets=assets,
            sentiment=sentiment,
            is_market_related=is_market_related,
            limit=limit
        )
        
        # æå–è§‚ç‚¹
        viewpoints = []
        for result in results:
            doc = result['document']
            if doc:
                # é™åˆ¶æ¯æ¡è§‚ç‚¹æœ€å¤š500å­—ç¬¦
                viewpoint = doc[:500] if len(doc) <= 500 else doc[:497] + "..."
                viewpoints.append(viewpoint)
        
        return jsonify({
            "trader_name": trader_name or "",
            "viewpoints": viewpoints,
            "error_reason": ""
        })
        
    except Exception as e:
        return jsonify({
            "trader_name": data.get("trader_name", "") if 'data' in locals() else "",
            "viewpoints": [],
            "error_reason": f"æœåŠ¡å™¨é”™è¯¯: {str(e)}"
        }), 500


@app.route('/query_by_name', methods=['POST'])
def query_by_name():
    """æ ¹æ®äº¤æ˜“å‘˜åç§°æŸ¥è¯¢ï¼ˆä½¿ç”¨æ··åˆæœç´¢ï¼ŒæŸ¥è¯¢æ–‡æœ¬ä¸ºäº¤æ˜“å‘˜åç§°ï¼‰
    
    è¯·æ±‚ä½“:
    {
        "trader_name": "Pentosh1",  # äº¤æ˜“å‘˜åç§°ï¼ˆå¿…éœ€ï¼‰
        "asset": "SOL",  # å•ä¸ªæ ‡çš„èµ„äº§ï¼ˆå¯é€‰ï¼Œå¦‚ "SOL"ï¼‰
                       # ç‰¹æ®Šå€¼ "blur" è¡¨ç¤ºä¸è¿›è¡Œèµ„äº§è¿‡æ»¤
        "assets": ["SOL", "BTC"],  # å¤šä¸ªæ ‡çš„èµ„äº§ï¼ˆå¯é€‰ï¼Œä¸ asset äºŒé€‰ä¸€ï¼‰
                                  # å¦‚æœåŒ…å« "blur"ï¼Œåˆ™ä¸è¿›è¡Œèµ„äº§è¿‡æ»¤
        "sentiment": "positive",  # æƒ…æ„Ÿï¼ˆå¯é€‰ï¼‰
        "is_market_related": true,  # æ˜¯å¦å¸‚åœºç›¸å…³ï¼ˆå¯é€‰ï¼‰
        "limit": 5  # è¿”å›ç»“æœæ•°é‡ï¼Œé»˜è®¤5
    }
    
    Note:
        - ä½¿ç”¨äº¤æ˜“å‘˜åç§°ä½œä¸ºæŸ¥è¯¢æ–‡æœ¬ï¼Œè¿›è¡Œæ··åˆæœç´¢
        - è¿™æ ·å¯ä»¥åŒæ—¶åˆ©ç”¨ BM25ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰å’Œå‘é‡ï¼ˆè¯­ä¹‰åŒ¹é…ï¼‰
        - BM25 åœ¨ documents å­—æ®µä¸Šæœç´¢ï¼ˆåŒ…å« text, info_overall_assessment, gpt_explanation, gpt_reasonï¼‰
    """
    try:
        data = request.get_json()
        trader_name = data.get("trader_name", "").strip()
        asset = data.get("asset", "").strip() or None
        assets = data.get("assets")  # å¯ä»¥æ˜¯åˆ—è¡¨æˆ– None
        if assets and isinstance(assets, list):
            assets = [a.strip() for a in assets if a and str(a).strip()]
            assets = assets if assets else None
        else:
            assets = None
        sentiment = data.get("sentiment", "").strip() or None
        is_market_related = data.get("is_market_related")
        limit = int(data.get("limit", 5))
        
        if not trader_name:
            return jsonify({
                "trader_name": "",
                "viewpoints": [],
                "error_reason": "äº¤æ˜“å‘˜åç§°ä¸ºç©º"
            })
        
        collection = get_collection()
        
        # ä½¿ç”¨äº¤æ˜“å‘˜åç§°ä½œä¸ºæŸ¥è¯¢æ–‡æœ¬ï¼Œè¿›è¡Œæ··åˆæœç´¢
        # è¿™æ ·å¯ä»¥åŒæ—¶åˆ©ç”¨ BM25ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰å’Œå‘é‡ï¼ˆè¯­ä¹‰åŒ¹é…ï¼‰
        results = hybrid_search(
            collection, 
            trader_name,  # æŸ¥è¯¢æ–‡æœ¬
            trader_name=trader_name,  # å…ƒæ•°æ®è¿‡æ»¤
            asset=asset,
            assets=assets,
            sentiment=sentiment,
            is_market_related=is_market_related,
            limit=limit
        )
        
        # æå–è§‚ç‚¹
        viewpoints = []
        for result in results:
            doc = result['document']
            if doc:
                viewpoint = doc[:500] if len(doc) <= 500 else doc[:497] + "..."
                viewpoints.append(viewpoint)
        
        return jsonify({
            "trader_name": trader_name,
            "viewpoints": viewpoints,
            "error_reason": ""
        })
        
    except Exception as e:
        return jsonify({
            "trader_name": data.get("trader_name", "") if 'data' in locals() else "",
            "viewpoints": [],
            "error_reason": f"æŸ¥è¯¢å¤±è´¥: {str(e)}"
        }), 500


if __name__ == '__main__':
    port = int(os.getenv('RAG_API_PORT', DEFAULT_PORT))
    host = os.getenv('RAG_API_HOST', '127.0.0.1')
    
    print(f"ğŸš€ å¯åŠ¨ ChromaDB RAG API æœåŠ¡ï¼ˆæ··åˆæœç´¢æ¨¡å¼ï¼‰...")
    print(f"   - åœ°å€: http://{host}:{port}")
    print(f"   - æ•°æ®åº“: {CHROMA_DB_PATH}")
    print(f"   - é›†åˆ: {COLLECTION_NAME}")
    print(f"   - Embedding æ¨¡å‹: {EMBEDDING_MODEL}")
    print(f"   - æœç´¢æ¨¡å¼: BM25 + å‘é‡æ··åˆæœç´¢ (RRF)")
    
    app.run(host=host, port=port, debug=False)
