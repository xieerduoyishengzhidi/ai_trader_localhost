"""
æµ‹è¯• HTML å…ƒæ•°æ®æå–åŠŸèƒ½
"""
import sys
import requests
from bs4 import BeautifulSoup
from datetime import datetime
import trafilatura

# è®¾ç½® Windows æ§åˆ¶å°ç¼–ç ä¸º UTF-8
if sys.platform == 'win32':
    import io
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8')

headers = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36'
}

def test_extract_metadata(url):
    """æµ‹è¯•ä» URL æå–å…ƒæ•°æ®"""
    print(f"\nğŸ” æµ‹è¯• URL: {url}")
    print("=" * 80)
    
    title = ""
    publish_time = None
    
    # æ–¹æ³•1: ä½¿ç”¨ trafilatura æå–å…ƒæ•°æ®
    print("\n1ï¸âƒ£ ä½¿ç”¨ trafilatura æå–å…ƒæ•°æ®:")
    try:
        downloaded = trafilatura.fetch_url(url)
        if downloaded:
            metadata = trafilatura.extract_metadata(downloaded)
            if metadata:
                print(f"   âœ… æ ‡é¢˜: {metadata.title}")
                print(f"   âœ… æ—¥æœŸ: {metadata.date}")
                print(f"   âœ… ä½œè€…: {metadata.author}")
                print(f"   âœ… æè¿°: {metadata.description[:100] if metadata.description else 'N/A'}...")
                
                if metadata.title:
                    title = metadata.title
                if metadata.date:
                    try:
                        publish_time = datetime.fromisoformat(str(metadata.date).replace('Z', '+00:00'))
                        print(f"   âœ… è§£æåçš„æ—¶é—´: {publish_time}")
                    except Exception as e:
                        print(f"   âš ï¸ æ—¶é—´è§£æå¤±è´¥: {e}")
            else:
                print("   âŒ trafilatura æœªæå–åˆ°å…ƒæ•°æ®")
    except Exception as e:
        print(f"   âŒ trafilatura æå–å¤±è´¥: {e}")
    
    # æ–¹æ³•2: ä» HTML ä¸­æå–
    print("\n2ï¸âƒ£ ä» HTML ä¸­æå–å…ƒæ•°æ®:")
    try:
        response = requests.get(url, headers=headers, timeout=10)
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # æå–æ ‡é¢˜
        print("\n   ğŸ“ æå–æ ‡é¢˜:")
        if not title:
            title_tag = soup.find('title')
            if title_tag:
                title = title_tag.get_text(strip=True)
                print(f"   âœ… <title> æ ‡ç­¾: {title}")
            else:
                print("   âŒ æœªæ‰¾åˆ° <title> æ ‡ç­¾")
        
        # æå–å‘å¸ƒæ—¶é—´
        print("\n   ğŸ“… æå–å‘å¸ƒæ—¶é—´:")
        time_selectors = [
            ('time[datetime]', 'time æ ‡ç­¾çš„ datetime å±æ€§'),
            ('meta[property="article:published_time"]', 'Open Graph å‘å¸ƒæ—¶é—´'),
            ('meta[name="publish-date"]', 'publish-date meta'),
            ('meta[name="date"]', 'date meta'),
            ('meta[property="article:published"]', 'article:published'),
            ('[class*="date"]', 'åŒ…å« date çš„ class'),
            ('[class*="time"]', 'åŒ…å« time çš„ class'),
        ]
        
        found_time = False
        for selector, desc in time_selectors:
            try:
                elem = soup.select_one(selector)
                if elem:
                    time_str = elem.get('datetime') or elem.get('content') or elem.get_text(strip=True)
                    if time_str:
                        print(f"   âœ… {desc}: {time_str}")
                        if not found_time:
                            try:
                                publish_time = datetime.fromisoformat(time_str.replace('Z', '+00:00'))
                                print(f"      âœ… è§£ææˆåŠŸ: {publish_time}")
                                found_time = True
                            except:
                                try:
                                    publish_time = datetime.strptime(time_str, '%Y-%m-%d %H:%M:%S')
                                    print(f"      âœ… è§£ææˆåŠŸ: {publish_time}")
                                    found_time = True
                                except Exception as e:
                                    print(f"      âš ï¸ è§£æå¤±è´¥: {e}")
            except:
                pass
        
        if not found_time:
            print("   âŒ æœªæ‰¾åˆ°å‘å¸ƒæ—¶é—´")
        
        # æ˜¾ç¤ºæ‰€æœ‰å¯èƒ½çš„ meta æ ‡ç­¾
        print("\n   ğŸ” æ‰€æœ‰ç›¸å…³çš„ meta æ ‡ç­¾:")
        meta_tags = soup.find_all('meta')
        relevant_metas = []
        for meta in meta_tags:
            prop = meta.get('property', '') or meta.get('name', '')
            content = meta.get('content', '')
            if any(kw in prop.lower() for kw in ['date', 'time', 'publish', 'article']):
                relevant_metas.append((prop, content))
        
        if relevant_metas:
            for prop, content in relevant_metas[:10]:  # åªæ˜¾ç¤ºå‰10ä¸ª
                print(f"      - {prop}: {content[:80]}")
        else:
            print("      âŒ æœªæ‰¾åˆ°ç›¸å…³ meta æ ‡ç­¾")
            
    except Exception as e:
        print(f"   âŒ HTML æå–å¤±è´¥: {e}")
    
    # æ€»ç»“
    print("\n" + "=" * 80)
    print("ğŸ“Š æå–ç»“æœæ€»ç»“:")
    print(f"   æ ‡é¢˜: {title[:80] if title else 'æœªæå–åˆ°'}")
    print(f"   å‘å¸ƒæ—¶é—´: {publish_time if publish_time else 'æœªæå–åˆ°'}")
    print("=" * 80)
    
    return title, publish_time

if __name__ == "__main__":
    # æµ‹è¯•å‡ ä¸ªçœŸå®çš„ CoinTelegraph URLï¼ˆä»å®é™…æŠ“å–çš„æ•°æ®ä¸­è·å–ï¼‰
    test_urls = [
        "https://cointelegraph.com/news/eu-crypto-regulations-imf-stablecoin-risk-global-express",
        "https://cointelegraph.com/news/bitcoin-treasury-firms-enter-darwinian-phase-as-premiums-collapse",
        "https://cointelegraph.com/news/clear-street-prepares-10b-ipo-as-crypto-treasury-boom-falters"
    ]
    
    print("ğŸ§ª å¼€å§‹æµ‹è¯• HTML å…ƒæ•°æ®æå–åŠŸèƒ½\n")
    
    for idx, url in enumerate(test_urls, 1):
        print(f"\n{'='*80}")
        print(f"æµ‹è¯• {idx}/{len(test_urls)}")
        print(f"{'='*80}")
        test_extract_metadata(url)
        if idx < len(test_urls):
            print("\nâ¸ï¸  ç­‰å¾…2ç§’åç»§ç»­ä¸‹ä¸€ä¸ªæµ‹è¯•...")
            import time
            time.sleep(2)

